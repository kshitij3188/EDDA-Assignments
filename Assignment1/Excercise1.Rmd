---
title: "Assignment 1"
author: "Kshitij Kavimandan, Pablo Alves, Pooja Mangal (Group 15)"
date: "20 February 2024"
output: pdf_document
fontsize: 11pt
highlight: tango
---

## Exercise 1. Ice cream

**a)** Relevant plots and normality assessment:

```{r}
# Load the dataset
ice_cream_dataset <- read.csv("Ice_cream.csv")
data = ice_cream_dataset$video
library("drcarlate")
```


```{r,fig.margin = TRUE,fig.width=6,fig.height=4,fig.align="centerr"}
# Do basic plots
par(mfrow=c(1,2)); hist(data); qqnorm(data); boxplot(data)
```

The histogram of the videogame scores looks normally distributed because it is roughly symetrical around 50, with values getting smaller towards its extremes. Despite this, the histogram bar for values between 60 and 65 is higher than what the corresponding analytical normal distribution should have.

Secondly, the Q-Q Plot also shows that our sample is densely populated in the center and its shape is very close to a line, which is also consistent with normality.

Finally, the boxplot is also consistent with normality, despite its median being not symetrical with its surrounding quantiles. As shown with the histogram, this can be explained with the additional values which are more frequently present in that particular region.

In short, our inspection of these basic plots suggest that this sample is normally distributed.

-----

Because we are assuming by definition that our sample is normally distributed, we can apply the 68-95-99.7% rule. Because our sample has a mean of 51.85 and a standard deviation of 9.9, we can then see that the desired 97% confidence interval for the mean should lie inside the 6 sigma interval, which has a length of 59.9. With this rough estimation, our 97% confidence value for our mean is 51.85 +- 29.7, which is akin to the [22.15,81.55] interval.

To get the 97% CI, we need to evaluate the margin of error with the formula

margin = T(0.97)*(std(x)/sqrt(N))

where T is the t distribution with N-1 degrees of freedom, N our sample size (200)...



```{r}
n <- length(data)
margin <- qt(0.97, df=n-1)*sd(data)/sqrt(n)
min_mean = mean(data) - margin
max_mean = mean(data) + margin
length = (max_mean - min_mean)/2; length
paste("97 CI: ", mean(data), " +-", length)
```

Thus, the 97% CI for the mean is [50.52571,53.1749], with a length of 2.648579


In order to compute the bounded 97% CI for mu, we need to use the following formula:

```{r}

m_calculator<-function(p, data) sqrt(sd(data)/length(data)*(4*norminv(p+(1-p)/2)))
margin = m_calculator(p=0.97,data=data)
min_mean = mean(data) - margin
max_mean = mean(data) + margin
length = max_mean - min_mean; length
paste("97 CI: ", mean(data)," +-", length)

```

In order to compute the neccesary number of samples needed for a particular maximun length of the CI we 
can use the following formula

```{r}

n_calculator <- function(p,length,data) sd(data)*(2*norminv(p+(1-p)/2)/length)^2
samples_needed = n_calculator(p=0.97,length=3,data=data)
paste("For a margin of: ", 3 ," we need", samples_needed)

```


To determine the 97% bootstrap CI we can apply the following code

```{r}
p = 0.97
B = 100

Tstar = numeric(B)
for(i in 1:B){Tstar[i]=mean(sample(data,replace=TRUE))}

Tstar985 = quantile(Tstar,0.985)
Tstar15 = quantile(Tstar, 0.015)

c(2*mean(Tstar) - Tstar985,2*mean(Tstar)-Tstar15)

d = ((2*mean(Tstar)-Tstar15) - (2*mean(Tstar) - Tstar985))
paste("Length:",d)
paste("Margin on each side:",d/2)

```

Our Bootstrap margin is bigger than our previous margins, which is consistent with the fact that the Bootstrap method does not assume normality, and thus is expected to have a bigger uncertainty on its estimation.

-----

**b)**

The t-test compares the mean of the sample to the hypothesized mean and calculates a t-statistic and a p-value.

```{r}
mu = 50
x = rnorm(length(data), mu, 1)
par(mfrow=c(1,2))
hist(x)
boxplot(x)
t_test_result <- t.test(x, alternative="g", mu = mu)
print(t_test_result)
t_test_result_mu_51 <- t.test(x, alternative="g", mu = 51)
t_test_result_mu_51
```

- In the first test, with mu_0 = 50, the p-value is more than the significance level of 0.05 which suggests that there isn't enough evidence to reject the null hypothesis, indicating that the mean score on the video game is not significantly different from 50. 

- Similarly, when testing against mu_0 = 51, the high p-value of 1 implies strong evidence in favor of the null hypothesis, meaning that the mean score is not significantly greater than 51.

- In the output, the 95% confidence interval for the first test is (49.9, infinity). This means that we are 95% confident that the true population mean lies in the above interval. The upper bound of infinity indicates that the upper limit is unbounded.

- The confidence interval for the second test is the same, as it is based on the sample mean and standard deviation. It doesn't change with the hypothesized mean mu_0.

**c)**

```{r}
# Sign test
sign_test <- binom.test(sum(data > 50), length(data), p = 0.5, alternative = "g")
print(sign_test)

# Test based on ranks (Wilcoxon signed-rank test)
wilcox_test <- wilcox.test(data, mu = 50, alternative = "g")
print(wilcox_test)

# Test for fraction of scores less than 42
binom_test <- binom.test(sum(data < 42), length(data), p = 0.25, alternative = "l")
print(binom_test)
```


- For the median score, the sign test results in a p-value of 0.144, suggesting no significant difference between the median score and mu_0 = 50. The 95% confidence interval for the success probability of the sign test ranges from 0.479 to 1.

- Comments on comparison of the above results with the previous question (b)):
*The t-test evaluates whether the mean score is significantly greater than 50, while the sign test assesses if the median score is greater than 50. Both tests yield p-values greater than 0.05, indicating that there's insufficient evidence to reject the null hypotheses. The confidence interval from the t-test provides a range of plausible values for the population mean, whereas the sign test directly assesses the proportion of observations above 50.*

- The Wilcoxon signed-rank test results in a p-value of 0.005, indicating a significant difference between the median score and mu_0 = 50. The alternative hypothesis suggests that the true location is greater than 50.

- Lastly, the binomial test to check the fraction of scores less than 42 yields a p-value of 0.0007, suggesting that the probability of success (scores less than 42) is less than 0.25. 

**d)**

```{r}
n = length(data); t=min(data); t
B = 100; tstar = numeric(B)
for (i in 1:B) {xstar=rexp(n,1)
 tstar[i]=min(xstar)}
pl = sum(tstar<t)/B; pr=sum(tstar>t)/B
p=2*min(pl,pr); p


# Define the test statistic function
test_statistic <- function(data) {
  return(min(data))
}

# Number of bootstrap samples
B <- 1000

# Bootstrap test
bootstrap_test <- function(mu) {
  tstar <- numeric(B)
  for (i in 1:B) {
    bootstrap_sample <- rnorm(B, mean = mu, sd = 10)  # Generate bootstrap sample
    tstar[i] <- test_statistic(bootstrap_sample)       # Compute minimum
  }
  
  # Compute observed minimum
  obs_min <- test_statistic(data[1:100])
  
  # Compute p-value
  p_value <- mean(tstar >= obs_min)
  
  # Determine if null hypothesis is rejected
  count <- 0
  if (p_value > 0.05) {
    reject_null <- TRUE
  } else {
    reject_null <- FALSE
    count <- count + 1
  }
  
  return(list(mu = mu, p_value = p_value, reject_null = reject_null))
}

# Perform bootstrap test for different values of mu in the range [0, 100]
results <- lapply(seq(0, 100, by = 1), bootstrap_test)

# Display results
for (result in results) {
  cat("mu:", result$mu, "p-value:", result$p_value, "Reject H0:", result$reject_null, "\n")
}
```

Since p-value=0.007, H0 is rejected.

```{r}
hist(tstar,prob=T, main="Histogram of tstar")
lines(rep(t,2),c(0,p), col="red",lwd=2)
axis(1,t,expression(paste("t")))
```


## Exercise 2. Hemoglobin in trout
**a)** R-code for randomization process:



## Exercise 3. Sour cream
**a)** Analyzing the data in a three-way experiment without interactions:














### Figures

You can also embed plots, for example:

```{r,echo=FALSE,fig.height=3.5}
plot(cars)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot. Use knitr options to style the output of a chunk. Place options in brackets above the chunk.
Other options with the defaults are: the `eval=FALSE` option just displays the R code (and does not run it); `warning=TRUE` whether to display warnings; `tidy=TRUE` wraps long code so it does not run off the page.

You can control the size and placement of figures. For example, 
you can put two figures (or more) next to each other. 
Use `par(mfrow=c(n,m))` to create `n` by `m` plots in one picture in R.
You can adjust the proportions of figures by using the `fig.width` 
and `fig.height` chunk options. These are specified in inches, 
and will be automatically scaled down to fit within the handout margin.
Chunk option `fig.align`  takes values `left`, `right`, or `center` 
(to align figures in the output document).

```{r,fig.margin = TRUE,fig.width=6,fig.height=3,fig.align="center"}
par(mfrow=c(1,2)); x1=rnorm(50); hist(x1); qqnorm(x1)
```

You can arrange for figures to span across the entire page by using 
the `fig.fullwidth` chunk option. 

```{r,fig.fullwidth=TRUE,fig.height=3}
plot(iris$Sepal.Length,iris$Petal.Length,xlab="Sepal.Length",ylab="Petal.Length")
```

More about chunk options can be found at [\color{blue}{\underline{https://yihui.name/knitr/options/}}](https://yihui.name/knitr/options/).


### Equations

To produce mathematical symbols, you can also include \LaTeX\ expessions/equations in your report:
inline $\frac{d}{dx}\left(\int_{0}^{x} f(u)\,du\right)=f(x)$ and 
in the display mode:
\[
\frac{d}{dx}\left( \int_{0}^{x} f(u)\,du\right)=f(x).
\]
To be able to use this functionality, \LaTeX\ has to be installed.
 
### Footnotes

Here is the use of a footnote^[This is a footnote.]. 


### Images
Want an image? This will do it. 
To depict an image (say, `my_image.png` which should be in your current working directory), use this command 

![caption for my image](my_image.png)

### Tables  

Want a table? This will create one (note that the separators 
*do not* have to be aligned).

Table Header  | Second Header
------------- | -------------
Table Cell    | Cell 2
Cell 3        | Cell 4 


You can also make table by using knit's `kable` function:

```{r echo=FALSE, results='asis'}
library(knitr)
kable(mtcars[1:5,],caption="A knit kable.")
```

### Block quote
> This will create a block quote, 
> if you want one.

### Verbatim
```
This text is displayed verbatim/preformatted.
```

### Links
Links: http://example.com, [in-text link to Google](http://google.com).

This is a \hyperlink{target1}{{\color{blue}{\underline{hyperlink}}}}.

\hypertarget{target1}{{\color{blue}{\underline{This}}}} is where the hyperlink jumps to.

### Itimization, italicized and embolded text
- Single asterisks italicize text *like this*. 
- Double asterisks embolden text **like this**.

One more way to italicize and embold: _italic_ and __bold__.
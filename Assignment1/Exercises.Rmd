---
title: "Assignment 1"
author: "Kshitij Kavimandan, Pablo Alves, Pooja Mangal (Group 15)"
date: "20 February 2024"
output: pdf_document
fontsize: 11pt
highlight: tango
---

## Exercise 1. Ice cream

**a)** Relevant plots and normality assessment:

We will create a histogram and a Q-Q plot of the sample of video game scores to visually assess normality.

```{r}
# Load the data
data <- read.csv("Ice_cream.csv")

# Plot histogram
hist(data$video, main="Histogram of Video Game Scores", xlab="Video Game Scores")

# Plot Q-Q plot
qqnorm(data$video)
qqline(data$video)
```

After examining the plots, we can comment on the normality of the video game scores.

### Constructing a bounded 97%-CI for $\mu$:

```{r}
# Calculate the mean and standard deviation of the sample
sample_mean <- mean(data$video)
sample_sd <- sd(data$video)

# Calculate the margin of error
margin_of_error <- qt(0.985, df = 
                        length(data$video) - 1) * (sample_sd / 
                                                     sqrt(length(data$video)))

# Construct the CI
lower_bound <- sample_mean - margin_of_error
upper_bound <- sample_mean + margin_of_error
```

### Sample size needed for a 97%-CI with a maximum length of 3:

```{r}
# Calculate the required sample size
required_sample_size <- (qt(0.985, df = 199) * sample_sd / 3) ^ 2
```

### Bootstrap 97%-CI for $\mu$:

```{r}
# Bootstrap function
bootstrap_mean <- function(data, sample_size) {
  bootstrap_samples <- replicate(10000, 
                                 mean(sample(data, sample_size, replace = TRUE)))
  ci_lower <- quantile(bootstrap_samples, 0.015)
  ci_upper <- quantile(bootstrap_samples, 0.985)
  return(c(ci_lower, ci_upper))
}

# Apply bootstrap function
bootstrap_ci <- bootstrap_mean(data$video, length(data$video))
```


**b)** T-test to verify mean score:

```{r}
# Perform t-test
t_test <- t.test(data$video, mu = 50, alternative = "greater")

# Print t-test results and explanation of CI
print(t_test)
```

Explanation of CI: The CI in the output represents the 95% confidence interval for the difference between the sample mean and the hypothesized mean ($\mu_0$). If the entire interval is above $\mu_0$, it suggests evidence for the alternative hypothesis.

**c)** Sign test and test based on ranks:

```{r}
# Perform sign test
sign_test <- binom.test(sum(data$video > 50), 
                        length(data$video), p = 0.5, alternative = "greater")

# Perform Wilcoxon signed-rank test
wilcox_test <- wilcox.test(data$video, mu = 50, alternative = "greater")

# Test for fraction of scores less than 42
binom_test <- binom.test(sum(data$video < 42), 
                         length(data$video), p = 0.25, alternative = "less")
```

**d)** Bootstrap test with test statistic T:

```{r}
# Bootstrap test function
bootstrap_test <- function(data, num_samples) {
  bootstrap_samples <- replicate(num_samples, 
                                 min(sample(data, length(data), replace = TRUE)))
  p_value <- mean(bootstrap_samples < min(data) | bootstrap_samples > 100)
  return(p_value)
}

# Apply bootstrap test
p_value <- bootstrap_test(data$video, 10000)

# Apply Kolmogorov-Smirnov test
ks_test <- ks.test(data$video, "pnorm", mean = 50, sd = 10)
```

**e)** Tests for male and female students:

```{r}
# Separate scores for male and female students
male_scores <- data$video[data$female == 0]
female_scores <- data$video[data$female == 1]

# Perform two-sample t-test
t_test_gender <- t.test(male_scores, female_scores, alternative = "greater")

# Perform Mann-Whitney test
mannwhitney_test <- wilcox.test(male_scores, female_scores, 
                                alternative = "greater")

# Perform Kolmogorov-Smirnov test
ks_test_gender <- ks.test(male_scores, female_scores)
```

f) Correlation and comparison between video game and puzzle scores:
```{r}
# Investigate correlation
correlation <- cor(data$video, data$puzzle)

# Test if puzzle scores are higher than video game scores
wilcox_test_puzzle <- wilcox.test(data$puzzle, data$video, alternative = "greater")
```

## Exercise 2. Hemoglobin in trout

a) R-code for randomization process:

```{r}
# Load the data
hemoglobin_data <- read.table("hemoglobin.txt", header = TRUE)

# Create a data frame to store the combinations of rate and method
combinations <- expand.grid(rate = c(1, 2, 3, 4), method = c("A", "B"))

# Randomly assign 80 fishes to the combinations
set.seed(123)  # Set seed for reproducibility
hemoglobin_data$fish <- sample(rep(1:80, 
                                   length.out = nrow(hemoglobin_data)),
                               replace = FALSE)

# Merge the combinations with the hemoglobin data
final_data <- merge(combinations, hemoglobin_data, by = "rate", all = TRUE)
```

**b)** Two-way ANOVA:

```{r}
# Perform two-way ANOVA
anova_result <- aov(hemoglobin ~ rate * method, data = hemoglobin_data)

# Print ANOVA table
print(summary(anova_result))
```

**c)** Influence of factors and combination yielding highest hemoglobin:

```{r}
# Calculate means for rate and method
mean_hemoglobin <- aggregate(hemoglobin ~ rate + method, 
                             data = hemoglobin_data, FUN = mean)

# Find combination yielding highest hemoglobin
max_hemoglobin <- mean_hemoglobin[which.max(mean_hemoglobin$hemoglobin), ]

# Estimate mean hemoglobin value for rate 3 by using method A
mean_hemoglobin_rate3_methodA <- 
  mean_hemoglobin$hemoglobin[which(mean_hemoglobin$rate == 3 & 
                                     mean_hemoglobin$method == "A")]

# Estimate mean hemoglobin value for each rate
mean_hemoglobin_rate <- aggregate(hemoglobin ~ rate, 
                                  data = hemoglobin_data, FUN = mean)
```

**d)** One-way ANOVA:

```{r}
# Perform one-way ANOVA ignoring the variable method
anova_result_rate <- aov(hemoglobin ~ rate, data = hemoglobin_data)

# Print ANOVA table
print(summary(anova_result_rate))
```

**e)** Kruskal-Wallis test:

```{r}
# Perform Kruskal-Wallis test
kruskal_test_result <- kruskal.test(hemoglobin ~ rate, data = hemoglobin_data)

# Print Kruskal-Wallis test result
print(kruskal_test_result)
```


## Exercise 3. Sour cream

**a)** Analyzing the data in a three-way experiment without interactions:

```{r}
# Load the data
cream_data <- read.table("cream.txt", header = TRUE)

# Fit the model without interactions
model <- lm(acidity ~ starter + batch + position, data = cream_data)

# Summary of the model
summary(model)
```

From the summary output, we can examine the coefficients and corresponding p-values for the effect of each factor. The p-value associated with the coefficient for starter 1 compared to starter 2 indicates whether there is a significant difference between the effects of these two starters on acidity. If the p-value is less than the chosen significance level (e.g., 0.05), we consider the difference to be statistically significant.

**b)** Removing insignificant block variables and performing ANOVA:

```{r}
# Fit the model with significant factors only
model <- lm(acidity ~ starter, data = cream_data)

# Perform ANOVA for the fixed effects model
anova_result <- anova(model)

# Print ANOVA table
print(anova_result)
```

**c)** Applying the Friedman test:

```{r}
# Convert "acidity" column to numeric
cream_data$acidity <- as.numeric(as.character(cream_data$acidity))

# Conduct the Friedman test
friedman_test_result <- friedman.test(cream_data$acidity, 
                                      cream_data$starter, cream_data$batch)

# Print the Friedman test result
print(friedman_test_result)
```

d) Performing a mixed effects analysis:

```{r}
# Load the lme4 package
library(lme4)

# Fit the mixed effects model
mixed_model <- lmer(acidity ~ (1|batch) + (1|position), data = cream_data)

# Summary of the mixed effects model
summary(mixed_model)
```
In the mixed effects model, we model the block variables (batch and position) as random effects. We compare the results from the mixed effects model to those from the fixed effects model to assess the impact of modeling block variables as random effects. This comparison helps evaluate the variability between batches and positions and provides insight into whether the fixed effects model adequately captures the underlying structure of the data.